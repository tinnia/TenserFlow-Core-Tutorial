##### [TenserFlow Core](https://www.tensorflow.org/tutorials?hl=ko)

## ì´ë¯¸ì§€ ë¶„ë¥˜


###### Reference

* [ì´ë¯¸ì§€](https://www.tensorflow.org/tutorials/load_data/images?hl=ko)
* [ì´ë¯¸ì§€ ë¶„ë¥˜](https://www.tensorflow.org/tutorials/images/classification?hl=ko)

<br />

### 1ï¸âƒ£ ë°ì´í„°ì…‹ ì¤€ë¹„

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤.
* numpy
* os
* PIL
* PIL.Image
* tenserflow
* tenserflow_datasets

tenserflow_datasets ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´, `conda install -c anaconda tensorflow-datasets`ì„ í†µí•´ ì„¤ì¹˜í•œ í›„ import


```python
import numpy as np
import os
import PIL
import PIL.Image
import tensorflow as tf
import tensorflow_datasets as tfds
```

**ê½ƒ ë°ì´í„°ì…‹**ì„ ë¡œë“œí•˜ê³  ì¤€ë¹„í•©ë‹ˆë‹¤.

flowers_photos/
  daisy/
  dandelion/
  roses/
  sunflowers/
  tulips/


```python
import pathlib

dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
data_dir = tf.keras.utils.get_file(origin=dataset_url, fname="flower_photos", untar=True)
data_dir = pathlib.Path(data_dir)
```

ë‹¤ìš´ë°›ì€ ë°ì´í„°ì…‹ì„ í™•ì¸í•©ë‹ˆë‹¤.


```python
image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count)
# 3670
```


ê° ë””ë ‰í† ë¦¬ì—ëŠ” í•´ë‹¹ ìœ í˜•ì˜ ê½ƒ ì´ë¯¸ì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.


```python
roses = list(data_dir.glob('roses/*'))
PIL.Image.open(str(roses[0]))
```


![png](assets/3/3-1.png)
    

<br />

### 2ï¸âƒ£ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°

keras.preprocessingì„ ì‚¬ìš©í•˜ì—¬ ë¡œë“œí•˜ê¸°

**image_dataset_from_directory**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë“¤ ì´ë¯¸ì§€ë¥¼ ë””ìŠ¤í¬ì— ë¡œë“œ


```python
batch_size = 32
img_height = 180
img_width = 180
```

* batch_size : ì „ì²´ íŠ¸ë ˆì´ë‹ ì…‹ì„ ì—¬ëŸ¬ ì‘ì€ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆˆ í•˜ë‚˜ì˜ ì†Œê·¸ë£¹ì— ì†í•˜ëŠ” ë°ì´í„° ìˆ˜ (ì „ì²´ ë°ì´í„°ë¥¼ ì‹ ê²½ë§ì— ë„£ìœ¼ë©´ í•™ìŠµì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ)


ê·¸ë¦¬ê³  ëª¨ë¸ì„ ê°œë°œí•˜ê¸° ì „ ê²€ì¦ ë¶„í• ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì•ì˜ fashion-mnistì™€ mnist ê°™ì€ ê²½ìš°ì—ëŠ” testì™€ train ë°ì´í„°ì…‹ì´ ë‚˜ëˆ„ì–´ì ¸ ìˆì—ˆì§€ë§Œ, ì§€ê¸ˆê³¼ ê°™ì€ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì€ ë¶„í• í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

train ë°ì´í„°ì…‹ì€ 80%, test ë°ì´í„°ì…‹ì€ 20%ë¡œ ë¶„í• í•©ë‹ˆë‹¤.


```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# Found 3670 files belonging to 5 classes.
# Using 2936 files for training.
```

```python
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# Found 3670 files belonging to 5 classes.
# Using 734 files for validation.
```


ë°ì´í„°ì…‹ì˜ `class_names` ì†ì„±ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
class_names = train_ds.class_names
print(class_names)
# ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']
```


<br />

### 3ï¸âƒ£ ë°ì´í„° ì‹œê°í™”, í‘œì¤€í™”í•˜ê¸°

##### ì‹œê°í™”


```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype('uint8'))
        plt.title(class_names[labels[i]])
        plt.axis("off")
```


![png](assets/3/3-2.png)
    


train ë°ì´í„°ì…‹ì˜ image_batchì™€ labels_batch ì˜ í…ì„œë¥¼ í™•ì¸í•´ë´…ë‹ˆë‹¤.


```python
for image_batch, label_batch in train_ds:
    print(image_batch.shape)
    print(label_batch.shape)
    break
    
# (32, 180, 180, 3)
# (32,)
```


* image_batchëŠ” (32, 180, 180, 3)ì˜ í…ì„œë¡œ 180*180*3ì˜ 32ê°œ ì´ë¯¸ì§€ ë°°ì¹˜ì…ë‹ˆë‹¤. (ì—¬ê¸°ì„œ 3ì€ RGBë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.)
* label_batchëŠ” (32,)ì˜ í…ì„œë¡œ 32ê°œì˜ ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” ë ˆì´ë¸”ì…ë‹ˆë‹¤.

<br />

##### í‘œì¤€í™”

RGBê°’ì€ 0 ~ 255 ë²”ìœ„ì´ê¸° ë•Œë¬¸ì—, ì‹ ê²½ë§ì— ì´ìƒì ì´ì§€ ì•Šì•„ì„œ Rescalingì„ í†µí•´ ê°’ì´ (0 ~ 1)ì‚¬ì´ì— ì˜¤ë„ë¡ í‘œì¤€í™”í•©ë‹ˆë‹¤.


```python
from tensorflow.keras import layers

normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)
```

* ì°¸ê³ : í”½ì…€ ê°’ì„ (-1,1)ìœ¼ë¡œ ì¡°ì •í•˜ë ¤ë©´ ëŒ€ì‹  `Rescaling(1./127.5, offset=-1)`ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br />

### 4ï¸âƒ£ ì„±ëŠ¥ì„ ìœ„í•œ ë°ì´í„°ì…‹ êµ¬ì„±í•˜ê¸°

ë²„í¼ë§ëœ í”„ë¦¬í˜ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ I/Oê°€ ì°¨ë‹¨ë˜ì§€ ì•Šê³  ë””ìŠ¤í¬ì—ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

* .cache() : ì²« ë²ˆì§¸ epochë™ì•ˆ ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•œ í›„ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ìœ ì§€í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë°ì´í„°ì…‹ì´ ë³‘ëª©ìƒíƒœê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì»¤ì„œ ë©”ëª¨ë¦¬ì— ë§ì§€ ì•ŠëŠ” ê²½ìš°, ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì´ ë†’ì€ ì˜¨ë””ìŠ¤í¬ ìºì‹œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* .prefetch() : í›ˆë ¨ ì¤‘ì— ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì‹¤í–‰ê³¼ ê²¹ì¹©ë‹ˆë‹¤.


```python
AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```

<br />

### 5ï¸âƒ£ ëª¨ë¸ ë§Œë“¤ê¸°

ëª¨ë¸ì€ ê°ê°ì— ìµœëŒ€ í’€ ë ˆì´ì–´ê°€ ìˆëŠ” 3ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.


* ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§ ëª¨ë¸
    * ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ : ì˜ìƒì²˜ë¦¬ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” Conv2D ë ˆì´ì–´ë¡œ í•„í„°ë¡œ íŠ¹ì§•ì„ ë½‘ì•„ì¤ë‹ˆë‹¤.
        * `Conv2D(32, (5, 5), padding='same', input_shape=(28, 28, 3), activation='rule')`
            * ì²« ë²ˆì§¸ ì¸ì : ì»¨ë³¼ë£¨ì…˜ í•„í„°ì˜ ìˆ˜
            * ë‘ ë²ˆì§¸ ì¸ì : (ì»¤ë„ì˜ í–‰, ì»¤ë„ì˜ ì—´)
            * padding : ê²½ê³„ì²˜ë¦¬ ë°©ë²• (valid - ìœ íš¨í•œ ì˜ì—­ë§Œ ì¶œë ¥ / same - ì¶œë ¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ ì…ë ¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì™€ ë™ì¼)
            * input_shape : ìƒ˜í”Œ ìˆ˜ë¥¼ ì œì™¸í•œ ì…ë ¥ í˜•íƒœë¥¼ ì •ì˜í•˜ëŠ”ë°, **ëª¨ë¸ì—ì„œ ì²« ë ˆì´ì–´ì¼ ë•Œë§Œ ì •ì˜í•˜ë©´ ë¨**
                * (í–‰, ì—´, ì±„ë„ ìˆ˜)ë¡œ ì •ì˜. ì—¬ê¸°ì„œ ì±„ë„ ìˆ˜ëŠ” í‘ë°±ì€ 1, ì»¬ëŸ¬(RGB)ëŠ” 3
            * activation : í™œì„±í™” í•¨ìˆ˜ ì„¤ì •
                * linear : ë””í´íŠ¸
                * relu : rectifer í•¨ìˆ˜ë¡œ ì€ìµì¸µì— ì£¼ë¡œ ì‚¬ìš©
                * sigmoid : ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì£¼ë¡œ ì‚¬ìš©
                * softmax : ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì£¼ë¡œ ì‚¬ìš©
    * Maxpooling : ë°ì´í„°ì˜ ì‚¬ì´ì¦ˆë¥¼ ê°•ì œë¡œ ì¤„ì´ê¸° ìœ„í•œ ê°œë…ìœ¼ë¡œ, ê·¸ ì•ˆì—ì„œ ê°€ì¥ í° ê°’ì„ ë½‘ì•„ë‚´ëŠ” ë°©ë²•
        * poolingì„ í•˜ëŠ” ì´ìœ  : overfittingì„ ë°©ì§€í•˜ê¸° ìœ„í•¨


```python
num_classes = 5

model = tf.keras.Sequential([
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
```

<br />

### 6ï¸âƒ£  ëª¨ë¸ ì»´íŒŒì¼ ë° í›ˆë ¨í•˜ê¸°


```python
model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
```


```python
model.summary()
```

![png](assets/3/3-6.png)



```python
epochs=10
history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)
```

![png](assets/3/3-7.png)


<br />

### 7ï¸âƒ£ í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”


```python
plt.figure(figsize=(8, 8))
# 1. Training and Validation Accuracy
plt.subplot(1, 2, 1)
plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')
plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# 2. Training and Validation Loss
plt.subplot(1, 2, 2)
plt.plot(range(epochs), history.history['loss'], label='Training Loss')
plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```


![png](assets/3/3-3.png)
    


ìœ„ì˜ ê·¸ë˜í”„ì™€ ê°™ì´ í›ˆë ¨ ì •í™•ì„±ê³¼ ê²€ì¦ ì •í™•ì„±ì— í° ì°¨ì´ê°€ ìˆìœ¼ë©°, ì•½ 60%ì˜ ì •í™•ì„±ë§Œ ë„ë‹¬í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” **ê³¼ëŒ€ì í•©**ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

###### ê³¼ì í•© ë°œìƒ ì´ìœ 
* ë°ì´í„°ê°€ ë„ˆë¬´ ì ì„ ê²½ìš°
* ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì˜ëª»í–ˆì„ ê²½ìš°
* Feature ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ê²½ìš°
  
###### ê³¼ì í•© ì¤„ì´ëŠ” ë°©ë²•
* ë°ì´í„° ì¦ê°•
* íŠ¹ì§•ì„ ì¤„ì´ê±°ë‚˜(ë“œëì•„ì›ƒ) ì •ê·œí™”í•˜ê¸°

<br />

### 8ï¸âƒ£ ê³¼ì í•© ë°©ì§€

##### ë°ì´í„° ì¦ê°•

ì¼ë°˜ì ìœ¼ë¡œ ê³¼ì í•©ì€ í›ˆë ¨ ì˜ˆì œê°€ ì ì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤. **ë°ì´í„° ì¦ê°•**ì€ ì¦ê°•í•œ ë‹¤ìŒ ë¯¿ì„ ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì„ì˜ ë³€í™˜ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•.


```python
data_augmentation = tf.keras.Sequential([
    layers.experimental.preprocessing.RandomFlip("horizontal", input_shape=(img_height, img_width, 3)),
    layers.experimental.preprocessing.RandomRotation(0.1),
    layers.experimental.preprocessing.RandomZoom(0.1)])
```

ë™ì¼í•œ ì´ë¯¸ì§€ì— ë°ì´í„° ì¦ê°•ì„ ì—¬ëŸ¬ ë²ˆ ì ìš©í•˜ì—¬ ì–´ë–»ê²Œ ì¦ê°•ì´ ë˜ëŠ”ì§€ ì‹œê°í™”í•´ë³´ê¸°


```python
plt.figure(figsize=(10, 10))
for images, _ in train_ds.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype('uint8'))
        plt.axis('off')
```


![png](assets/3/3-4.png)
    


<br />

##### ë“œë¡­ì•„ì›ƒ

ê³¼ì í•©ì„ ì¤„ì´ëŠ” ë˜ ë‹¤ë¥¸ ê¸°ìˆ ì€ ì •ê·œí™”ì˜ í•œ í˜•íƒœì¸ **ë“œë¡­ì•„ì›ƒ**ì„ ë„ì…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ë©´, í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— ë ˆì´ì–´ì—ì„œ ì—¬ëŸ¬ ì¶œë ¥ ë‹¨ìœ„ê°€ ë¬´ì‘ìœ„ë¡œ ë“œë¡­ì•„ì›ƒë©ë‹ˆë‹¤. ë“œë¡­ì•„ì›ƒì€ 0.1, 0.2, 0.4 ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ì†Œìˆ˜ë¥¼ ì…ë ¥ ê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì´ëŠ” ì ìš©ëœ ë ˆì´ì–´ì—ì„œ ì¶œë ¥ ë‹¨ìœ„ì˜ 10%, 20% ë˜ëŠ” 40%ë¥¼ ì„ì˜ë¡œ ì œê±°í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

**ë°ì´í„° ì¦ê°•, ë“œë¡­ì•„ì›ƒì„ ì ìš©í•œ ëª¨ë¸ì„ ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ í›ˆë ¨í•´ë´…ë‹ˆë‹¤.**


```python
model = tf.keras.Sequential([
  data_augmentation,      # ì¦ê°•í•œ ë°ì´í„°ì…‹
  layers.experimental.preprocessing.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),    # ë“œë¡­ì•„ì›ƒ
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
```

<br />

### 9ï¸âƒ£ ëª¨ë¸ ì»´íŒŒì¼ ë° í›ˆë ¨í•˜ê¸°


```python
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
```


```python
model.summary()
```

![png](assets/3/3-8.png)


ì´ì œ, ì´ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.


```python
epochs = 15
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)
```

![png](assets/3/3-9.png)


<br />

### ğŸ”Ÿ í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”í•˜ê¸°


```python
plt.figure(figsize=(8, 8))
# 1. Training and Validation Accuracy
plt.subplot(1, 2, 1)
plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')
plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# 2. Training and Validation Loss
plt.subplot(1, 2, 2)
plt.plot(range(epochs), history.history['loss'], label='Training Loss')
plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```


![png](assets/3/3-5.png)
    

